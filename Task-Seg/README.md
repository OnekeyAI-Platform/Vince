## PoseSegFusion

**Abstract**

Purpose: The quantity and quality of skeletal muscle and adipose tissue is an important prognostic factor for clinical outcomes across several illnesses. Clinically acquired computed tomography (CT) scans are commonly used for quantification of body composition, but manual analysis is laborious and costly. The primary aim of this study was to develop and evaluate a fully automated algorithm for segmenting the abdomen from CT to quantify body composition. 

Materials and Methods: This study utilized CT imaging data from 280 patients in the training set. The performance of three convolutional neural network (CNN) models—Deeplabv3, U-Net, and U-Net++—was initially assessed, and based on these results, a novel segmentation fusion model was developed. Axial CT images at the level of the third lumbar vertebra were selected for analysis, with manual labeling of regions of interest for muscle, intermuscular adipose tissue (IMAT), visceral adipose tissue (VAT), and subcutaneous adipose tissue (SAT). The model was evaluated on 120 internal validation cases and 103 external test cases. The evaluation metrics included the Dice similarity coefficient, intersection over union (IoU), false positive rate (FPR), precision, recall, and cross-sectional area (CSA) error. Additionally, a visual analysis of the segmentation results was performed. 

Results: In the external test set, the Dice coefficients for U-Net, U-Net++, and the fusion model were 0.9514±0.0137, 0.9521±0.0144, and 0.9537±0.0134, respectively, which were significantly superior to the performance of the deeplabv3_resnet101 model and the deeplabv3_resnet50 model. Regarding CSA error, the fusion model showed high accuracy in both the internal validation and external test sets. Specifically, in the internal validation set, the average CSA errors for muscle, IMAT, SAT, and VAT were 0.97%, 5.56%, 1.17%, and 2.04%, respectively, while in the external test set, the corresponding error values were 0.84%, 5.21%, 0.91%, and 1.59%. IMAT exhibited the highest average error in both datasets (over 5%), whereas muscle had the lowest average error (below 1%). Additionally, the fusion model demonstrated strong performance on other evaluation metrics. Except for IMAT, the Dice coefficients, precision, and recall for muscle, SAT, and VAT were all above 0.96, and the IoU exceeded 0.9. In contrast, IMAT showed a higher FPR, with lower Dice coefficients, IoU, accuracy, and recall compared to the other three tissues. 

Conclusion: The fusion model combining Deeplabv3, U-Net, and U-Net++ demonstrated exceptional performance and accuracy in the automatic segmentation of muscle, IMAT, VAT, and SAT in L3-level CT images. This approach is beneficial for the rapid and precise clinical assessment of sarcopenia.